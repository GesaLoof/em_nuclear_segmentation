{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b609a8-d181-4588-a0b6-91b2891106e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fibsem_tools.io import read_xarray\n",
    "from napari import Viewer\n",
    "from xarray_ome_ngff import read_multiscale_group\n",
    "from tifffile import imwrite\n",
    "from skimage.transform import resize\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from tifffile import imread, imwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4af1c-2a9c-4d26-ae66-f1dbd75c6e26",
   "metadata": {},
   "source": [
    "### collect 3D crop from cellmap annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e21ca-3b82-4d1a-881d-6d025d6415ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through all metadata and find closest res\n",
    "#assuming data is saved as z, y, x\n",
    "def find_closest_res_match_x_y(em_parent_path, resolution_2D):\n",
    "    res_dict = {}\n",
    "    em_parent_path = Path(em_parent_path)\n",
    "    em_xarray = read_xarray(em_parent_path, storage_options={'anon': True})\n",
    "    for dict in em_xarray.attrs[\"multiscales\"][0][\"datasets\"]:\n",
    "        resolution_level = dict[\"path\"]\n",
    "        scale = dict[\"coordinateTransformations\"][0][\"scale\"]\n",
    "        scale_2D = (scale[1], scale[2])\n",
    "        res_diff = abs(np.array(resolution_2D) - scale_2D)\n",
    "        res_dict[resolution_level] = res_diff\n",
    "    smallest_diff = min(res_dict, key=lambda k: res_dict[k].sum())\n",
    "    return smallest_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2149a6-5937-4f1a-9ab3-31db825ca11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_crops_of_specific_resolution_2d(resolution, base_path, em_out_path, gt_out_path, organelle, count = 1):\n",
    "    em_parent_path = f'{base_path}/em/fibsem-uint8/'\n",
    "    print(em_parent_path)\n",
    "    #find closest match in resolution and create desired path to em\n",
    "    resolution_s = find_closest_res_match_x_y(em_parent_path, resolution)\n",
    "    em_path = f'{base_path}/em/fibsem-uint8/{resolution_s}'\n",
    "    \n",
    "    # Read the EM data as an xarray DataArray\n",
    "    em_parent = read_xarray(em_parent_path, storage_options={'anon': True})\n",
    "    em_data = read_xarray(em_path, storage_options={'anon': True})\n",
    "    \n",
    "    # get ground truth\n",
    "    path_to_gt = f'{base_path}/labels/groundtruth/'\n",
    "    path = Path(path_to_gt)\n",
    "    subfolders = [p for p in path.iterdir() if p.is_dir()]\n",
    "    sorted_subfolders = sorted(subfolders, key=lambda x: int(re.findall(r'\\d+', str(x))[-1]))\n",
    "    print(path_to_gt)\n",
    "\n",
    "    \n",
    "    # iterate through gt crops\n",
    "    crop_dict = {}\n",
    "    for crop_path in sorted_subfolders:\n",
    "        crop_number = str(crop_path).split(\"/\")[-1]\n",
    "        print(f'processing {crop_number}')\n",
    "        labels_parent_path = f'{crop_path}/{organelle}/'\n",
    "        labels_path = f'{crop_path}/{organelle}/{resolution_s}'\n",
    "    \n",
    "        # get metadata info (except if there is no gt for the organelle of choice)\n",
    "        try:\n",
    "            labels_parent = read_xarray(labels_parent_path, storage_options={'anon': True})\n",
    "        except:\n",
    "            print(f'{organelle} not in ground truth for this dataset')\n",
    "            continue\n",
    "        res_index = int(resolution_s.split(\"s\")[-1])\n",
    "        print(f\"{res_index=}\")\n",
    "        crop_offset_world = np.array(labels_parent.attrs[\"multiscales\"][0][\"datasets\"][res_index]['coordinateTransformations'][1]['translation'])\n",
    "        em_offset_world = np.array(em_parent.attrs[\"multiscales\"][0][\"datasets\"][res_index]['coordinateTransformations'][1]['translation'])\n",
    "        crop_resolution = np.array(labels_parent.attrs[\"multiscales\"][0][\"datasets\"][res_index]['coordinateTransformations'][0]['scale'])\n",
    "        em_resolution = np.array(em_parent.attrs[\"multiscales\"][0][\"datasets\"][res_index]['coordinateTransformations'][0]['scale'])\n",
    "        em_resolution_str = \"[\" + \",\".join(map(str, em_resolution)) + \"]\"\n",
    "        # Get label data and shape\n",
    "        labels_data = read_xarray(labels_path, storage_options={'anon': True})\n",
    "        labels_shape = labels_data.shape  # e.g., (200, 200, 200)\n",
    "\n",
    "        # check if there are any labels of interest in this crop\n",
    "        labels = np.unique(labels_data)\n",
    "        if len(list(labels)) <= 1 and np.unique(labels_data) == 0:\n",
    "            print(f\"{crop_number} has no nuclear annotation\")\n",
    "            print(count)\n",
    "            continue\n",
    "        print(count)\n",
    "        #calculate difference in resolution between EM iage and annotations\n",
    "        ratio_resolution = crop_resolution/em_resolution\n",
    "            \n",
    "        # relative_offset_world = crop_offset_world #- em_offset_world\n",
    "        offset_voxels = np.round(crop_offset_world / em_resolution).astype(int)\n",
    "        \n",
    "        # starting point of the crop\n",
    "        z0, y0, x0 = map(int, offset_voxels)\n",
    "        #size of the crop (resolution difference taken into account)\n",
    "        dz, dy, dx = map(int,(labels_shape * ratio_resolution))\n",
    "        #ez, ey, ex = em_data.shape\n",
    "        \n",
    "        # Extract matching crop from EM starting from top left\n",
    "        em_crop = em_data[z0:z0+dz, y0:y0+dy, x0:x0+dx]\n",
    "    \n",
    "        #if resolution is different, scale up gt data to  match em data\n",
    "        if not em_crop.shape[0]*em_crop.shape[1]*em_crop.shape[2] > 32000000000:\n",
    "            print(\"smaller than 32GB --> processing image crop\")\n",
    "            if (ratio_resolution != np.zeros_like(ratio_resolution)).all():\n",
    "                print(\"different resolutions - rescaling gt data\")\n",
    "                resized_mask = resize(\n",
    "                labels_data,\n",
    "                output_shape=em_crop.shape,  # height, width\n",
    "                order=0,  # nearest-neighbor for masks\n",
    "                preserve_range=True,\n",
    "                anti_aliasing=False\n",
    "                ).astype(labels_data.dtype)\n",
    "    \n",
    "            else:\n",
    "                print(\"same resolution\")\n",
    "        \n",
    "            # make sure the mask is binary\n",
    "            resized_mask[resized_mask > 0] = 1\n",
    "            print(type(em_crop))\n",
    "            print(em_crop.dtype)\n",
    "            print(em_crop.shape)\n",
    "            \n",
    "            #save EM crop and annotation as tiff in seperate folders\n",
    "            imwrite(f'{em_out_path}/em_image_sample{count}.tif' , em_crop)\n",
    "            \n",
    "            imwrite(f'{gt_out_path}/ground_truth_sample{count}.tif', resized_mask)\n",
    "            crop_dict[count] = (crop_path, resolution_s, em_resolution_str)\n",
    "            count += 1\n",
    "\n",
    "    return count, crop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893860a-3fe1-412f-9685-f44eba129adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define resolution level and path to EM data\n",
    "#resolution_s = 2\n",
    "organelle = 'nuc'\n",
    "em_out_path = '/Users/gloof/Desktop/data/cellmap_2d_training_data_nuc/em_161225_s_adapted_13_4nm/'\n",
    "gt_out_path = '/Users/gloof/Desktop/data/cellmap_2d_training_data_nuc/gt_161225_s_adapted_13_4nm/'\n",
    "if not os.path.exists(em_out_path):\n",
    "    os.mkdir(em_out_path)\n",
    "    os.mkdir(gt_out_path)\n",
    "    \n",
    "path_to_data = '/Users/gloof/Desktop/code/cellmap-segmentation-challenge/data/'\n",
    "path = Path(path_to_data)\n",
    "subfolders = [p for p in path.iterdir() if p.is_dir()]\n",
    "\n",
    "csv_file = '/Users/gloof/Desktop/data/cellmap_2d_training_data_nuc/crop_summary_161225_s_adapted_13_4.csv'\n",
    "fieldnames = ['count', 'path_to_crop', 'resolution_level', 'scale']\n",
    "\n",
    "# Write header only if file doesn't exist\n",
    "if not os.path.exists(csv_file):\n",
    "    with open(csv_file, mode='w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "resolution = (13.4,13.4)   # x and y      \n",
    "count = 1\n",
    "for folder in subfolders:\n",
    "    name = str(folder).split('/')[-1]\n",
    "    base_path = f'{path_to_data}{name}/{name}.zarr/recon-1'\n",
    "    count, crop_dict = get_em_crops_of_specific_resolution_2d(resolution, base_path, em_out_path, gt_out_path, organelle, count)\n",
    "    with open(csv_file, mode='a', newline='') as f:\n",
    "        for key in crop_dict.keys():\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            writer.writerow({'count': key, 'path_to_crop': crop_dict[key][0], \"resolution_level\": crop_dict[key][1], \"scale\": crop_dict[key][2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2627b3-60dd-495b-8029-c6e0ff949c46",
   "metadata": {},
   "source": [
    "### split 3D crops and annotations into 2D images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0b2b0-d678-4719-bbee-769200a4a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_planes(input_path):\n",
    "    \"\"\"\n",
    "    Loads a 3D .tif and returns list of 2D planes.\n",
    "    \"\"\"\n",
    "    volume = imread(input_path)\n",
    "    if volume.ndim != 3:\n",
    "        raise ValueError(\"The input image is not 3D (Z, Y, X).\")\n",
    "    return [volume[z, :, :] for z in range(volume.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8405c9-2f0e-4d31-8dde-74fac8c2fba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 1\n",
    "\n",
    "em_dir = \"/Users/gloof/Desktop/data/cellmap_2d_training_data_nuc/em_161225_s_adapted_13_4nm/\"\n",
    "gt_dir = \"/Users/gloof/Desktop/data/cellmap_2d_training_data_nuc/gt_161225_s_adapted_13_4nm/\"\n",
    "em_out_dir = \"/Users/gloof/Desktop/data/cellmap_2d_training_data_nuc/em_2D_161225_s_adapted_13_4nm/\"\n",
    "gt_out_dir = \"/Users/gloof/Desktop/data/cellmap_2d_training_data_nuc/gt_2D_161225_s_adapted_13_4nm/\"\n",
    "\n",
    "os.makedirs(em_out_dir, exist_ok=True)\n",
    "os.makedirs(gt_out_dir, exist_ok=True)\n",
    "\n",
    "for em_file in glob.glob(os.path.join(em_dir, \"*.tif\")):\n",
    "    name = em_file.split(\"_\")[-1].split(\".\")[0]\n",
    "    print(f\"Processing {name=}\")\n",
    "\n",
    "    gt_files = glob.glob(os.path.join(gt_dir, f\"*{name}.tif\"))\n",
    "    if not gt_files:\n",
    "        print(f\"No GT match for {name}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    gt_file = gt_files[0]\n",
    "\n",
    "    em_planes = split_into_planes(em_file)\n",
    "    gt_planes = split_into_planes(gt_file)\n",
    "\n",
    "    if len(em_planes) != len(gt_planes):\n",
    "        print(f\"Mismatch in planes for {name}: EM={len(em_planes)}, GT={len(gt_planes)}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    for em_plane, gt_plane in zip(em_planes, gt_planes):\n",
    "        if np.all(em_plane == 0) or np.all(gt_plane == 0):\n",
    "            print(f\"Skipping image_{count}.tif (all-zero detected)\")\n",
    "        else:\n",
    "            em_out_path = os.path.join(em_out_dir, f\"image_{count}.tif\")\n",
    "            gt_out_path = os.path.join(gt_out_dir, f\"image_{count}.tif\")\n",
    "            imwrite(em_out_path, em_plane)\n",
    "            imwrite(gt_out_path, gt_plane)\n",
    "        count += 1\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316436b7-46f6-4b75-9ba1-5cdda64c71a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
